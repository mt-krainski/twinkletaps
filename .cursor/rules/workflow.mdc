---
alwaysApply: true
---

# Agentic Development Rules: Jira + Small Reviewable Increments

## Goals

* Mimic a normal software development lifecycle with clear stages: **Plan → Build → Review → Merge**.
* Use **Jira** (project `GFD`) as the source of truth for tasks and status.
* Optimize for **small, reviewable, testable increments**:

  * Target **~200-300 lines changed** per task (guideline, not a hard cap).
  * **Invariant: the application must build and run successfully after every task.** A task that leaves the app in a broken state (e.g. DB schema out of sync with ORM, missing imports, broken contracts between layers) is not a valid increment — even if a subsequent task would fix it.
  * Each task must produce a **coherent, verifiable increment** (not "half a feature").

* Make work easy to audit:

  * Every change set links back to a **Jira issue key**.
  * Each task includes verification steps, test plan, and (when applicable) PR/branch metadata.

---

## Jira Workflow

**Project:** `GFD` — https://gravitalforge.atlassian.net  
**MCP server:** `user-gravitalforge-atlassian`

Issue statuses and their transition IDs:

| Status      | Transition ID | Meaning                                  |
| ----------- | ------------- | ---------------------------------------- |
| To Do       | `11`          | Approved and ready to implement          |
| In Progress | `21`          | Currently being implemented              |
| Review      | `2`           | Implemented; PR open, awaiting review    |
| Done        | `31`          | Merged to mainline                       |

Use `jira_transition_issue` to move issues between statuses.  
Use `jira_get_issue` / `jira_search` to read issue content.  
Use `jira_create_issue` to create new issues.  
Use `jira_update_issue` to update fields.  
Use `jira_add_comment` to post branch name, PR URL, or status updates as comments.

**Board placement:** Issues created via `jira_create_issue` are automatically placed on the board with a rank assigned. No manual step required.

**Issue types:**
- `Epic` — a feature or theme grouping related tasks
- `Task` — an implementation task linked to an Epic

---

## Task IDs

Issue keys are auto-assigned by Jira (e.g. `GFD-42`). IDs are immutable.

Epics group related tasks. Tasks reference their parent Epic via the `parent` field.

---

## Jira Issue Description Template

When creating a Task, use this structure in the Jira description (Markdown):

```markdown
## Problem / Goal

[What user value this delivers. 1-3 sentences.]

### Non-Goals

[Explicitly state what is out of scope.]

---

## Acceptance Criteria

- [Observable outcome 1]
- [Observable outcome 2]
- [How to verify the feature works]

---

## Repo Context

- **Files:** [paths to files/components involved]
- **Patterns:** [existing patterns to follow]
- **Related:** [relevant prior code/modules]

---

## Implementation Plan (Small & Concrete)

[Steps with expected code touchpoints. Include exact file paths.]

**Estimated size:** ~NNN LOC.

---

## Test Plan

- [Unit/integration/e2e updates required]
- [Exact commands to run]
- [Fixtures/mocks needed]

---

## Verification Notes

[Manual validation steps (if applicable). Screenshots/log snippets expected (optional).]

---

## Risk / Rollback

[What could break, and how to rollback safely. This is only relevant for changes that actually need a rollback strategy. E.g. database changes. The default rollback strategy is to roll-back the deployment to the previous version. This is only relevant if for some reason that is not possible or dangerous.]
```

Branch name and PR URL are posted as **Jira comments** on the issue, not embedded in the description body.

---

## Stage Responsibilities and Rules

### Analysis & Planning

**Agent must:**

0. Ask clarifying questions if the request is ambiguous before proceeding. Err on the side of asking.
1. **Scan the repo** to understand:

   * Architecture, conventions, test setup, CI, linters, code ownership patterns.

2. Identify:

   * Where changes should live.
   * Existing helpers/utilities to reuse.
   * Risks and unknowns.

3. Produce an **implementation plan**:

   * implementation plan should consist of an overview of work needed to be done - think of this as an explicit list of things to do
   * implementation plan breaks the work down into smaller tasks:
      * Each task is a coherent increment (not half a feature).
      * Aim for ~200-300 LOC change per task.
      * Each task must be testable/verifiable in isolation.
      * If one feature is large, split by **vertical slices** (thin end-to-end capability) or by **preparatory refactor** that is independently valuable.
      * After each change, the application must remain functioning. E.g. it's not acceptable to have one task modify the database schema and a second task modify the prisma orm definition of that schema

**Task decomposition rules**

* ✅ Good splits:

  * "Add auth middleware + tests" (complete behavior + verification)
  * "Add DB migration + read API endpoint + tests" (complete path)
  * "Introduce shared utility + refactor two call sites + tests" (coherent cleanup enabling next steps)

* ❌ Bad splits:

  * "Add half of endpoint logic" then "add rest of endpoint logic"
  * "Add UI skeleton" with nothing runnable or testable
  * "Run DB migration to rename tables" then "update ORM schema and app code to match" — the app is broken between these two tasks
  * Any split where task N changes a contract (schema, API, types) and task N+1 updates the consumers — the app must not be broken in between

Dos and don'ts:
- make each task clear and descriptive


**Output artifacts**

* Present the plan and **wait for human approval**.
* After human accepts the plan, create a Jira Epic (if one doesn't exist) and individual Task issues in Jira using `jira_create_issue`.
* Tasks should reference the parent Epic.

---

### Ready (Human gate)

**Human responsibility**

* Select next task(s) to execute.
* Optionally edit acceptance criteria or priorities in Jira.

**Agent responsibility**

* Do not start multiple tasks in parallel unless explicitly instructed.
* When starting a task: the user provides the issue key. Transition it to `In Progress` via `jira_transition_issue`. If no key is provided, query with `jira_search` using `project = GFD AND status = "To Do" ORDER BY priority`.
* Focus on exactly one work item at a time. Feel free to read the Epic for additional context.

---

### Development

**Agent must:**

0. Transition issue to `In Progress` via `jira_transition_issue`.
1. Create a branch:

   * `task/<ISSUE_KEY>/<slug>`

2. Implement strictly according to the task scope.
3. Keep changes within the targeted review size; if scope expands:

   * Stop and create a follow-up task in Jira; do not silently balloon.

4. Update tests and docs necessary for the increment.
5. Run the project's standard checks locally (as available).

**Definition of Done for Development**

* Acceptance criteria satisfied.
* Test plan implemented and runnable.
* No obvious lint/type failures introduced.
* **Application builds and runs successfully** — verify with the project's build command. The app must not be left in a broken state.
* Post branch name and PR URL as Jira comments on the issue via `jira_add_comment` (branch name once branched; PR URL once opened).

**Then**

* Fire up lint and tests for the repo.
* If everything green — invoke the **finishing-a-development-branch** skill ("wrap"). That skill owns the Review transition, PR creation, user assignment, and Jira comment. **Do not transition to `Review` directly from development.**

---

### Review & Merge

**When an agent is assigned a task in `Review` status**, it means the human has handed it back for action. The agent must first determine what is being asked:

1. Fetch Jira issue comments: `jira_get_issue` (check the `comment` field).
2. Fetch PR comments: use `gh api` on the PR linked in the issue comments (both review comments and general conversation — see the `addressing-pr-comments` skill).
3. Determine the intent:
   - If there are clear review comments or change requests → address them using the **addressing-pr-comments** skill, then re-run lint/tests, push, and leave a reply.
   - If there is **no clear indication** of what is needed → read `humanAtlassianId` from `.cursor.workflow`, reassign the issue to the human via `jira_update_issue`, and add a `jira_add_comment` explicitly asking: "Assigned back to you — could you clarify what you'd like me to do? (e.g. address specific comments, make a change, or something else)"

**Agent (when invoked for a code review pass) must:**

* Re-read the task requirements and compare with the change.
* Check for:

  * Correctness, edge cases, security/regression risks
  * Consistency with repo patterns
  * Test adequacy (what's missing)
  * Documentation / comments where needed
  * Ensure tests pass (this can also be done by checking CI)

* Provide a concise review report:

  * "Pass / Needs changes"
  * Specific required edits

**Human responsibility**

* Final sanity check; optionally run smoke tests.

**If changes required**

* Leave the issue in `Review`. Add a Jira comment with the required changes and re-assign the issue to the agent (bot) to address.

**If accepted**

* Verify all CI is green (if applicable).
* Ensure the Jira issue has the PR link posted as a comment and verification evidence.
* Merge the PR and transition issue to `Done` via `jira_transition_issue`.
* Optionally append release note or changelog reference if your repo uses it.

---

## Pull Requests and Linking

* PR title format: `[GFD-###] <Title>`
* PR description must include:

  * Issue key (`GFD-###`)
  * What changed
  * How to test
  * Risks/rollback notes

Post the PR URL as a Jira comment on the issue after creation.

---

## Quality Bar (Non-Negotiables)

* Follow existing architecture and naming conventions.
* Prefer reuse over invention.
* No dead code, commented-out blocks, or "temporary hacks" without explicit task notes.
* Every behavior change must have:

  * Tests OR a clearly documented reason why tests are not feasible, plus manual verification steps.
* Keep diffs reviewable:

  * Avoid large mechanical refactors mixed with feature work unless the task is explicitly a refactor task.

---

## User-Specific Configuration

Workflow parameters that vary per user are stored in `.cursor.workflow` at the repo root (shell `key=value` format). **Read this file before any step that requires user-specific values.**

If `.cursor.workflow` does not exist, **stop and ask the user to create it** before continuing. Explain that the file should be placed at the repo root and contain:

```sh
humanAtlassianId="<your Jira username>"   # plain username, not email — e.g. "matt"
```

To find the correct username: it is the short login name shown in Jira profile settings (not the display name, not the email address).

| Key                 | Usage                                                        |
| ------------------- | ------------------------------------------------------------ |
| `humanAtlassianId`  | Jira username of the human — used when assigning tasks to the human for review or decision |

**Assignee format:** Jira's `assignee` field requires a plain string username — not an email address and not an object. Example: `fields: {"assignee": "matt"}`. Read the value from `humanAtlassianId` in `.cursor.workflow`.

**Identity clarification:**
- `humanAtlassianId` — the human developer. Use this when handing off a task to the human (review, blocker resolution, etc.).
- The Atlassian MCP credentials belong to the **AI bot** (the agent itself). When the user says "assign to you" or refers to the agent as the owner of a task, the bot's identity is already embedded in the MCP connection — no explicit assignee field is needed.

---

## Operating Mode: How You (the Human) Invoke Agents

You will typically do:

1. Invoke **Planner Agent** with a description of the work:

   * Output: plan presented for approval → Epic + Tasks created in Jira (`To Do`).
2. Pick next issue and invoke **Builder Agent** on that Jira issue:

   * Output: code + issue transitioned to `Review`.
3. Invoke **Reviewer Agent** on the issue:

   * Output: review notes; pass → merge + transition to `Done`, fail → leave in `Review` with comment for agent.

---

## Default Assumptions (Override Per Repo)

* Branch naming: `task/GFD-###/<slug>`
* Commit messages: `GFD-###: <short message>`
* PR title: `[GFD-###] <Title>`
* Test commands: use the repo's documented defaults; if missing, the agent must infer and document the commands used.
